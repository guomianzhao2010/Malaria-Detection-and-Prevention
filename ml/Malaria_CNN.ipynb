{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Malaria Cell Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Dropout,Dense,Flatten,BatchNormalization,Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in malaria cell images\n",
    "infected = glob.glob('../Datasets/cell_images/Parasitized/*.png')\n",
    "uninfected = glob.glob('../Datasets/cell_images/Uninfected/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5,000 infected images and 5,000 uninfected images\n",
    "print(f\"{len(infected)} infected cell images\")\n",
    "print(f\"{len(uninfected)} uninfected cell images\")\n",
    "print(f\"Shape of first infected cell image: {cv2.imread(infected[0]).shape}\")\n",
    "print(f\"Shape of first uninfected cell image: {cv2.imread(uninfected[0]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhibit 4 sample images of infected cells\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(1,5):\n",
    "    plt.subplot(1,4,i)\n",
    "    value = np.random.randint(100)\n",
    "    image = cv2.imread(infected[value])\n",
    "    plt.imshow(image)\n",
    "    plt.title('Infected Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhibit 4 sample images of uninfected cells\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(1,5):\n",
    "    plt.subplot(1,4,i)\n",
    "    value = np.random.randint(100)\n",
    "    image = cv2.imread(uninfected[value])\n",
    "    plt.imshow(image)\n",
    "    plt.title('Uninfected Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original images consist in RGB coefficients in the 0-255, but such values would be too high for our model to process\n",
    "# (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255\n",
    "augmentor = ImageDataGenerator(rescale=1./255, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19292 images belonging to 2 classes.\n",
      "Found 8266 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create the training and testing datasets\n",
    "train_generator = augmentor.flow_from_directory('../Datasets/cell_images/', batch_size=32,\n",
    "                                                target_size = (96,96), class_mode = 'binary', subset = 'training')\n",
    "test_generator = augmentor.flow_from_directory('../Datasets/cell_images/', batch_size=32, target_size=(96,96),\n",
    "                                               class_mode='binary', subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "\n",
    "# batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers\n",
    "# reduces overfitting\n",
    "model1.add(BatchNormalization())\n",
    "\n",
    "# max pooling helps with overfitting by reducing sample's dimensionality and allowing for assumptions \n",
    "# to be made about features contained in the sub-regions binned\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "\n",
    "# dropout keeps a certain proportion of nodes from being used each go around (help prevent overfitting)\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "model1.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Dropout(0.4))\n",
    "model1.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "# flatten changes the dimensions of the data to make it an input layer for the artificial neural network\n",
    "model1.add(Flatten())\n",
    "\n",
    "# A dense layer is used to change the dimensions of the vector. \n",
    "# Mathematically speaking, it applies a rotation, scaling, translation transform to the vector.\n",
    "model1.add(Dense(64,activation='relu'))\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "# The Sigmoid function takes any range real number and returns the output value which falls in the range of 0 to 1.\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_custom = model1.fit_generator(train_generator, steps_per_epoch=100,\n",
    "                              epochs = 5,validation_data=test_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"Malaria_CNN_Trained1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\eyang1\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\eyang1\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\eyang1\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 328s 2s/step - loss: 1.0576 - acc: 0.5481 - val_loss: 0.6509 - val_acc: 0.6328\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 336s 2s/step - loss: 0.6570 - acc: 0.5955 - val_loss: 0.6163 - val_acc: 0.6906\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 324s 2s/step - loss: 0.6452 - acc: 0.6005 - val_loss: 0.6314 - val_acc: 0.6781\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.6232 - acc: 0.6134 - val_loss: 0.6284 - val_acc: 0.6844\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 330s 2s/step - loss: 0.6052 - acc: 0.6308 - val_loss: 0.6677 - val_acc: 0.6531\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 329s 2s/step - loss: 0.5166 - acc: 0.7063 - val_loss: 0.4250 - val_acc: 0.8266\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 335s 2s/step - loss: 0.4527 - acc: 0.7819 - val_loss: 0.8172 - val_acc: 0.5500\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 327s 2s/step - loss: 0.3869 - acc: 0.8234 - val_loss: 0.5505 - val_acc: 0.7937\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 328s 2s/step - loss: 0.3609 - acc: 0.8383 - val_loss: 0.3134 - val_acc: 0.8746\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 332s 2s/step - loss: 0.3267 - acc: 0.8712 - val_loss: 0.2640 - val_acc: 0.8859\n"
     ]
    }
   ],
   "source": [
    "# removed a convolutional layer with 32 filters to speed up the model training process\n",
    "# training and validation accuracies appear to be unstable (used 80/20 training validation split)\n",
    "model2 = Sequential()\n",
    "model2.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(64,activation='relu'))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom2 = model2.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"Malaria_CNN_Trained2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 329s 2s/step - loss: 0.7726 - acc: 0.5372 - val_loss: 0.6810 - val_acc: 0.6797\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 316s 2s/step - loss: 0.6765 - acc: 0.5819 - val_loss: 0.7245 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 330s 2s/step - loss: 0.6685 - acc: 0.6017 - val_loss: 0.6233 - val_acc: 0.7047\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 314s 2s/step - loss: 0.6714 - acc: 0.6031 - val_loss: 0.6345 - val_acc: 0.6687\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 309s 2s/step - loss: 0.6639 - acc: 0.6023 - val_loss: 0.6670 - val_acc: 0.6125\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 308s 2s/step - loss: 0.6614 - acc: 0.5998 - val_loss: 0.6327 - val_acc: 0.7266\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 313s 2s/step - loss: 0.6585 - acc: 0.6000 - val_loss: 0.6682 - val_acc: 0.5749\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 308s 2s/step - loss: 0.6428 - acc: 0.6150 - val_loss: 0.5665 - val_acc: 0.7188\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 309s 2s/step - loss: 0.6319 - acc: 0.6278 - val_loss: 0.5999 - val_acc: 0.7125\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 319s 2s/step - loss: 0.6040 - acc: 0.6623 - val_loss: 0.4865 - val_acc: 0.8109\n"
     ]
    }
   ],
   "source": [
    "# changed the last hidden dense layer to 32 filters instead of 64\n",
    "# training and validation accuracies still seem unstable (used 80/20 training validation split)\n",
    "model3 = Sequential()\n",
    "model3.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Dropout(0.4))\n",
    "\n",
    "model3.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Dropout(0.4))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(32,activation='relu'))\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Dense(1,activation='sigmoid'))\n",
    "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom3 = model3.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"Malaria_CNN_Trained3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 353s 2s/step - loss: 0.7144 - acc: 0.6023 - val_loss: 0.6885 - val_acc: 0.6406\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 350s 2s/step - loss: 0.6214 - acc: 0.6572 - val_loss: 0.5453 - val_acc: 0.7219\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 349s 2s/step - loss: 0.4530 - acc: 0.7909 - val_loss: 0.3465 - val_acc: 0.8688\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.2560 - acc: 0.9133 - val_loss: 0.3722 - val_acc: 0.9047\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.1934 - acc: 0.9383 - val_loss: 0.2402 - val_acc: 0.9169\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 331s 2s/step - loss: 0.2049 - acc: 0.9369 - val_loss: 0.2281 - val_acc: 0.9344\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 327s 2s/step - loss: 0.1939 - acc: 0.9417 - val_loss: 0.4439 - val_acc: 0.7484\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 327s 2s/step - loss: 0.1903 - acc: 0.9436 - val_loss: 0.2130 - val_acc: 0.9094\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 325s 2s/step - loss: 0.1661 - acc: 0.9491 - val_loss: 0.2423 - val_acc: 0.9313\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 328s 2s/step - loss: 0.1610 - acc: 0.9487 - val_loss: 0.3795 - val_acc: 0.8531\n"
     ]
    }
   ],
   "source": [
    "# added another hidden convolutional layer with 64 filters\n",
    "# training and validation accuracies appear more stable now (used 80/20 training validation split)\n",
    "model4 = Sequential()\n",
    "model4.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(64,activation='relu'))\n",
    "model4.add(Dropout(0.4))\n",
    "model4.add(Dense(1,activation='sigmoid'))\n",
    "model4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom4 = model4.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save(\"Malaria_CNN_Trained4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 339s 2s/step - loss: 0.6721 - acc: 0.6359 - val_loss: 0.8683 - val_acc: 0.5734\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 333s 2s/step - loss: 0.5125 - acc: 0.7494 - val_loss: 0.4784 - val_acc: 0.8422\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 336s 2s/step - loss: 0.3223 - acc: 0.8780 - val_loss: 0.2370 - val_acc: 0.9203\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 333s 2s/step - loss: 0.2581 - acc: 0.9089 - val_loss: 0.1749 - val_acc: 0.9422\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 332s 2s/step - loss: 0.2000 - acc: 0.9437 - val_loss: 0.1894 - val_acc: 0.9516\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 336s 2s/step - loss: 0.2042 - acc: 0.9363 - val_loss: 0.1755 - val_acc: 0.9609\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.1950 - acc: 0.9403 - val_loss: 0.1352 - val_acc: 0.9547\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 330s 2s/step - loss: 0.1746 - acc: 0.9448 - val_loss: 0.2762 - val_acc: 0.8859\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 350s 2s/step - loss: 0.1687 - acc: 0.9480 - val_loss: 0.1526 - val_acc: 0.9484\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 340s 2s/step - loss: 0.1645 - acc: 0.9528 - val_loss: 0.2568 - val_acc: 0.9016\n"
     ]
    }
   ],
   "source": [
    "# training and validation accuracies appear stabilized now (used 70/30 training validation split)\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Dropout(0.4))\n",
    "\n",
    "model5.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Dropout(0.4))\n",
    "\n",
    "model5.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Dropout(0.4))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(64,activation='relu'))\n",
    "model5.add(Dropout(0.4))\n",
    "model5.add(Dense(1,activation='sigmoid'))\n",
    "model5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom5 = model5.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save(\"Malaria_CNN_Trained5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.6863 - acc: 0.5944 - val_loss: 1.0100 - val_acc: 0.4547\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 339s 2s/step - loss: 0.6206 - acc: 0.6464 - val_loss: 4.3948 - val_acc: 0.5375\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 352s 2s/step - loss: 0.3983 - acc: 0.8243 - val_loss: 0.4677 - val_acc: 0.8689\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.2624 - acc: 0.9069 - val_loss: 0.4070 - val_acc: 0.8469\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.2204 - acc: 0.9277 - val_loss: 0.3124 - val_acc: 0.9375\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.2266 - acc: 0.9329 - val_loss: 0.1581 - val_acc: 0.9516\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.1909 - acc: 0.9430 - val_loss: 0.4121 - val_acc: 0.8344\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1862 - acc: 0.9464 - val_loss: 0.2082 - val_acc: 0.9391\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 352s 2s/step - loss: 0.1671 - acc: 0.9514 - val_loss: 0.2370 - val_acc: 0.9031\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 348s 2s/step - loss: 0.1902 - acc: 0.9428 - val_loss: 0.2336 - val_acc: 0.9328\n"
     ]
    }
   ],
   "source": [
    "# changed the last hidden dense layer from 64 to 32 filters\n",
    "# training and validation accuracies appear stabilized now (used 70/30 training validation split)\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(2,2))\n",
    "model6.add(Dropout(0.4))\n",
    "\n",
    "model6.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(2,2))\n",
    "model6.add(Dropout(0.4))\n",
    "\n",
    "model6.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(MaxPooling2D(2,2))\n",
    "model6.add(Dropout(0.4))\n",
    "\n",
    "model6.add(Flatten())\n",
    "\n",
    "model6.add(Dense(32,activation='relu'))\n",
    "model6.add(Dropout(0.4))\n",
    "model6.add(Dense(1,activation='sigmoid'))\n",
    "model6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom6 = model6.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save(\"Malaria_CNN_Trained6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 325s 2s/step - loss: 0.7038 - acc: 0.6146 - val_loss: 1.1786 - val_acc: 0.5141\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 324s 2s/step - loss: 0.5510 - acc: 0.7205 - val_loss: 0.8871 - val_acc: 0.7344\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 337s 2s/step - loss: 0.3431 - acc: 0.8592 - val_loss: 0.4831 - val_acc: 0.8641\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 325s 2s/step - loss: 0.2538 - acc: 0.9097 - val_loss: 0.3298 - val_acc: 0.8531\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 326s 2s/step - loss: 0.2175 - acc: 0.9295 - val_loss: 0.1560 - val_acc: 0.9515\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 330s 2s/step - loss: 0.2011 - acc: 0.9400 - val_loss: 0.3269 - val_acc: 0.8922\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 331s 2s/step - loss: 0.1906 - acc: 0.9444 - val_loss: 0.1731 - val_acc: 0.9422\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 340s 2s/step - loss: 0.1959 - acc: 0.9416 - val_loss: 0.2367 - val_acc: 0.9531\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.1877 - acc: 0.9411 - val_loss: 0.1896 - val_acc: 0.9453\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.1750 - acc: 0.9459 - val_loss: 0.2339 - val_acc: 0.9281\n"
     ]
    }
   ],
   "source": [
    "# changed the number of filters in the layers to 32, 64, 32, 64\n",
    "# training and validation accuracies appear stabilized now (used 70/30 training validation split)\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(2,2))\n",
    "model7.add(Dropout(0.4))\n",
    "\n",
    "model7.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(2,2))\n",
    "model7.add(Dropout(0.4))\n",
    "\n",
    "model7.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(MaxPooling2D(2,2))\n",
    "model7.add(Dropout(0.4))\n",
    "\n",
    "model7.add(Flatten())\n",
    "\n",
    "model7.add(Dense(64,activation='relu'))\n",
    "model7.add(Dropout(0.4))\n",
    "model7.add(Dense(1,activation='sigmoid'))\n",
    "model7.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom7 = model7.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.save(\"Malaria_CNN_Trained7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 360s 2s/step - loss: 0.7311 - acc: 0.6184 - val_loss: 1.2160 - val_acc: 0.5875\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 358s 2s/step - loss: 0.4514 - acc: 0.7834 - val_loss: 0.5345 - val_acc: 0.8609\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 342s 2s/step - loss: 0.2590 - acc: 0.9050 - val_loss: 0.2621 - val_acc: 0.9219\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 353s 2s/step - loss: 0.2235 - acc: 0.9286 - val_loss: 0.2124 - val_acc: 0.9125\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 365s 2s/step - loss: 0.1995 - acc: 0.9384 - val_loss: 0.1766 - val_acc: 0.9391\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1928 - acc: 0.9431 - val_loss: 0.1314 - val_acc: 0.9484\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 350s 2s/step - loss: 0.1887 - acc: 0.9409 - val_loss: 0.3819 - val_acc: 0.7328\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 359s 2s/step - loss: 0.1653 - acc: 0.9491 - val_loss: 0.2085 - val_acc: 0.9353\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.1720 - acc: 0.9478 - val_loss: 0.1883 - val_acc: 0.9422\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 334s 2s/step - loss: 0.1675 - acc: 0.9478 - val_loss: 0.1562 - val_acc: 0.9484\n"
     ]
    }
   ],
   "source": [
    "# added another hidden convolutional layer with 32 filters\n",
    "# model accuracies did not increase by a significant amount (used 70/30 training validation split)\n",
    "# should stick with model 7 \n",
    "model8 = Sequential()\n",
    "model8.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(MaxPooling2D(2,2))\n",
    "model8.add(Dropout(0.4))\n",
    "\n",
    "model8.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(MaxPooling2D(2,2))\n",
    "model8.add(Dropout(0.4))\n",
    "\n",
    "model8.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(MaxPooling2D(2,2))\n",
    "model8.add(Dropout(0.4))\n",
    "\n",
    "model8.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(MaxPooling2D(2,2))\n",
    "model8.add(Dropout(0.4))\n",
    "\n",
    "model8.add(Flatten())\n",
    "\n",
    "model8.add(Dense(64,activation='relu'))\n",
    "model8.add(Dropout(0.4))\n",
    "model8.add(Dense(1,activation='sigmoid'))\n",
    "model8.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom8 = model8.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.save(\"Malaria_CNN_Trained8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 353s 2s/step - loss: 0.7185 - acc: 0.5878 - val_loss: 0.9234 - val_acc: 0.5125\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 337s 2s/step - loss: 0.5658 - acc: 0.7202 - val_loss: 0.9609 - val_acc: 0.6922\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 351s 2s/step - loss: 0.3531 - acc: 0.8667 - val_loss: 0.2609 - val_acc: 0.9219\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.2487 - acc: 0.9169 - val_loss: 0.3267 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 349s 2s/step - loss: 0.2196 - acc: 0.9277 - val_loss: 0.3048 - val_acc: 0.9203\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 353s 2s/step - loss: 0.2036 - acc: 0.9354 - val_loss: 0.2642 - val_acc: 0.9359\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 336s 2s/step - loss: 0.1865 - acc: 0.9408 - val_loss: 0.1941 - val_acc: 0.9422\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 349s 2s/step - loss: 0.1929 - acc: 0.9425 - val_loss: 0.4000 - val_acc: 0.9031\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 349s 2s/step - loss: 0.1925 - acc: 0.9451 - val_loss: 0.1220 - val_acc: 0.9688\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 357s 2s/step - loss: 0.1655 - acc: 0.9500 - val_loss: 0.3012 - val_acc: 0.9142\n"
     ]
    }
   ],
   "source": [
    "# changed the number of filters to 32, 64, 32, 64, 32\n",
    "# model accuracies did not increase by a significant amount (used 70/30 training validation split)\n",
    "# should stick with model 7 \n",
    "\n",
    "model9 = Sequential()\n",
    "model9.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model9.add(BatchNormalization())\n",
    "model9.add(MaxPooling2D(2,2))\n",
    "model9.add(Dropout(0.4))\n",
    "\n",
    "model9.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model9.add(BatchNormalization())\n",
    "model9.add(MaxPooling2D(2,2))\n",
    "model9.add(Dropout(0.4))\n",
    "\n",
    "model9.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model9.add(BatchNormalization())\n",
    "model9.add(MaxPooling2D(2,2))\n",
    "model9.add(Dropout(0.4))\n",
    "\n",
    "model9.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model9.add(BatchNormalization())\n",
    "model9.add(MaxPooling2D(2,2))\n",
    "model9.add(Dropout(0.4))\n",
    "\n",
    "model9.add(Flatten())\n",
    "\n",
    "model9.add(Dense(32,activation='relu'))\n",
    "model9.add(Dropout(0.4))\n",
    "model9.add(Dense(1,activation='sigmoid'))\n",
    "model9.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom9 = model9.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.save(\"Malaria_CNN_Trained9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 366s 2s/step - loss: 0.8309 - acc: 0.5491 - val_loss: 0.8394 - val_acc: 0.6188\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 387s 2s/step - loss: 0.6527 - acc: 0.6306 - val_loss: 1.1778 - val_acc: 0.5156\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 411s 2s/step - loss: 0.5117 - acc: 0.7456 - val_loss: 1.0495 - val_acc: 0.6859\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 393s 2s/step - loss: 0.3464 - acc: 0.8731 - val_loss: 0.3363 - val_acc: 0.8812\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.2401 - acc: 0.9209 - val_loss: 0.2346 - val_acc: 0.9328\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 343s 2s/step - loss: 0.2163 - acc: 0.9367 - val_loss: 0.3236 - val_acc: 0.9156\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 339s 2s/step - loss: 0.1953 - acc: 0.9422 - val_loss: 0.2904 - val_acc: 0.9187\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 341s 2s/step - loss: 0.1983 - acc: 0.9389 - val_loss: 0.2191 - val_acc: 0.9391\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 360s 2s/step - loss: 0.1638 - acc: 0.9470 - val_loss: 0.3698 - val_acc: 0.8953\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 347s 2s/step - loss: 0.1910 - acc: 0.9411 - val_loss: 0.2002 - val_acc: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# added another hidden convolutional layer with 32 filters\n",
    "# model accuracies did not increase by a significant amount (used 70/30 training validation split)\n",
    "# should stick with model 7 \n",
    "model10 = Sequential()\n",
    "model10.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model10.add(BatchNormalization())\n",
    "model10.add(MaxPooling2D(2,2))\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model10.add(BatchNormalization())\n",
    "model10.add(MaxPooling2D(2,2))\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model10.add(BatchNormalization())\n",
    "model10.add(MaxPooling2D(2,2))\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model10.add(BatchNormalization())\n",
    "model10.add(MaxPooling2D(2,2))\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model10.add(BatchNormalization())\n",
    "model10.add(MaxPooling2D(2,2))\n",
    "model10.add(Dropout(0.4))\n",
    "\n",
    "model10.add(Flatten())\n",
    "\n",
    "model10.add(Dense(32,activation='relu'))\n",
    "model10.add(Dropout(0.4))\n",
    "model10.add(Dense(1,activation='sigmoid'))\n",
    "model10.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom10 = model10.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.save(\"Malaria_CNN_Trained10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 603s 3s/step - loss: 0.7026 - acc: 0.6314 - val_loss: 1.0437 - val_acc: 0.7031\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 579s 3s/step - loss: 0.4521 - acc: 0.7861 - val_loss: 0.2388 - val_acc: 0.9045\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 584s 3s/step - loss: 0.2770 - acc: 0.8952 - val_loss: 0.1983 - val_acc: 0.9313\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.2272 - acc: 0.9272 - val_loss: 0.2200 - val_acc: 0.9344\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 582s 3s/step - loss: 0.2135 - acc: 0.9311 - val_loss: 0.3023 - val_acc: 0.9156\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 576s 3s/step - loss: 0.1876 - acc: 0.9439 - val_loss: 0.2123 - val_acc: 0.9391\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 562s 3s/step - loss: 0.1846 - acc: 0.9445 - val_loss: 0.1650 - val_acc: 0.9469\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 560s 3s/step - loss: 0.1788 - acc: 0.9414 - val_loss: 0.1458 - val_acc: 0.9656\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 553s 3s/step - loss: 0.1665 - acc: 0.9480 - val_loss: 0.1508 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 564s 3s/step - loss: 0.1575 - acc: 0.9517 - val_loss: 0.1353 - val_acc: 0.9531\n"
     ]
    }
   ],
   "source": [
    "# removed a hidden convolutional layer\n",
    "# changed number of filters to 64, 32, 64, 32, 64\n",
    "# model accuracies did not increase by a significant amount (used 70/30 training validation split)\n",
    "# should stick with model 7 \n",
    "\n",
    "model11 = Sequential()\n",
    "model11.add(Convolution2D(64,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model11.add(BatchNormalization())\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Dropout(0.4))\n",
    "\n",
    "model11.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model11.add(BatchNormalization())\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Dropout(0.4))\n",
    "\n",
    "model11.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model11.add(BatchNormalization())\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Dropout(0.4))\n",
    "\n",
    "model11.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model11.add(BatchNormalization())\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Dropout(0.4))\n",
    "\n",
    "model11.add(Flatten())\n",
    "\n",
    "model11.add(Dense(64,activation='relu'))\n",
    "model11.add(Dropout(0.4))\n",
    "model11.add(Dense(1,activation='sigmoid'))\n",
    "model11.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom11 = model11.fit_generator(train_generator, steps_per_epoch=200,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.save(\"Malaria_CNN_Trained11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 1479s 3s/step - loss: 0.5683 - acc: 0.7123 - val_loss: 1.0512 - val_acc: 0.8113\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1538s 3s/step - loss: 0.2407 - acc: 0.9192 - val_loss: 0.2354 - val_acc: 0.9303\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1553s 3s/step - loss: 0.1910 - acc: 0.9396 - val_loss: 0.2146 - val_acc: 0.9481\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1485s 3s/step - loss: 0.1794 - acc: 0.9458 - val_loss: 0.3489 - val_acc: 0.9131\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1496s 3s/step - loss: 0.1651 - acc: 0.9511 - val_loss: 0.1605 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1506s 3s/step - loss: 0.1571 - acc: 0.9504 - val_loss: 0.2065 - val_acc: 0.9444\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1496s 3s/step - loss: 0.1596 - acc: 0.9499 - val_loss: 0.1725 - val_acc: 0.9442\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1478s 3s/step - loss: 0.1522 - acc: 0.9531 - val_loss: 0.2011 - val_acc: 0.9394\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1548s 3s/step - loss: 0.1538 - acc: 0.9531 - val_loss: 0.1395 - val_acc: 0.9537\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1472s 3s/step - loss: 0.1499 - acc: 0.9538 - val_loss: 0.1885 - val_acc: 0.9481\n"
     ]
    }
   ],
   "source": [
    "# increased steps per epoch from 200 to 500 (everything else is from model 11)\n",
    "# increased validation steps from 20 to 50\n",
    "# model accuracies did not increase by a significant amount (used 70/30 training validation split)\n",
    "# should stick with model 7 \n",
    "\n",
    "model12 = Sequential()\n",
    "model12.add(Convolution2D(64,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model12.add(BatchNormalization())\n",
    "model12.add(MaxPooling2D(2,2))\n",
    "model12.add(Dropout(0.4))\n",
    "\n",
    "model12.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model12.add(BatchNormalization())\n",
    "model12.add(MaxPooling2D(2,2))\n",
    "model12.add(Dropout(0.4))\n",
    "\n",
    "model12.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model12.add(BatchNormalization())\n",
    "model12.add(MaxPooling2D(2,2))\n",
    "model12.add(Dropout(0.4))\n",
    "\n",
    "model12.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model12.add(BatchNormalization())\n",
    "model12.add(MaxPooling2D(2,2))\n",
    "model12.add(Dropout(0.4))\n",
    "\n",
    "model12.add(Flatten())\n",
    "\n",
    "model12.add(Dense(64,activation='relu'))\n",
    "model12.add(Dropout(0.4))\n",
    "model12.add(Dense(1,activation='sigmoid'))\n",
    "model12.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom12 = model12.fit_generator(train_generator, steps_per_epoch=500,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12.save(\"Malaria_CNN_Trained12.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 981s 2s/step - loss: 0.6536 - acc: 0.6362 - val_loss: 0.5486 - val_acc: 0.7556\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 863s 2s/step - loss: 0.3462 - acc: 0.8508 - val_loss: 0.2418 - val_acc: 0.9202\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 888s 2s/step - loss: 0.1915 - acc: 0.9399 - val_loss: 0.7857 - val_acc: 0.5819\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 964s 2s/step - loss: 0.1717 - acc: 0.9459 - val_loss: 0.1751 - val_acc: 0.9381\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 874s 2s/step - loss: 0.1574 - acc: 0.9517 - val_loss: 0.3479 - val_acc: 0.8344\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 842s 2s/step - loss: 0.1524 - acc: 0.9534 - val_loss: 0.1562 - val_acc: 0.9525\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 921s 2s/step - loss: 0.1473 - acc: 0.9541 - val_loss: 0.2070 - val_acc: 0.9290\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 867s 2s/step - loss: 0.1392 - acc: 0.9570 - val_loss: 0.1470 - val_acc: 0.9494\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 877s 2s/step - loss: 0.1303 - acc: 0.9580 - val_loss: 0.1669 - val_acc: 0.9544\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 877s 2s/step - loss: 0.1285 - acc: 0.9572 - val_loss: 0.1924 - val_acc: 0.9344\n"
     ]
    }
   ],
   "source": [
    "# increased steps per epoch from 200 to 500 (everything else is from model 7)\n",
    "# increased validation steps from 20 to 50\n",
    "# model accuracies became slightly unstable\n",
    "# should stick with model 7 \n",
    "\n",
    "model13 = Sequential()\n",
    "model13.add(Convolution2D(32,(3,3),activation='relu',input_shape = (96,96,3)))\n",
    "model13.add(BatchNormalization())\n",
    "model13.add(MaxPooling2D(2,2))\n",
    "model13.add(Dropout(0.4))\n",
    "\n",
    "model13.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "model13.add(BatchNormalization())\n",
    "model13.add(MaxPooling2D(2,2))\n",
    "model13.add(Dropout(0.4))\n",
    "\n",
    "model13.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model13.add(BatchNormalization())\n",
    "model13.add(MaxPooling2D(2,2))\n",
    "model13.add(Dropout(0.4))\n",
    "\n",
    "model13.add(Flatten())\n",
    "\n",
    "model13.add(Dense(64,activation='relu'))\n",
    "model13.add(Dropout(0.4))\n",
    "model13.add(Dense(1,activation='sigmoid'))\n",
    "model13.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_custom13 = model13.fit_generator(train_generator, steps_per_epoch=500,\n",
    "                              epochs = 10,validation_data=test_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13.save(\"Malaria_CNN_Trained13.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 7 is the best of the ones trained. Some other models have slightly higher accuracies, but they had an extra hidden layer. The small increase in accuracy was not high enough to justify adding another hidden layer. In this case, it is better to use the slightly simpler model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
